<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="./images/icon.png">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title>Publications </title> --->
<title>Hai X. Pham personal website</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<div id="header-icon-container" >
<a href="index.html"><img src="./images/profile2.png" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
<div id="header-text-container">
<a href="index.html">Hai X. Pham's personal website</a>
</div>
</div>
<div id="main">
<button class="openbtn" onclick="openNav()">☰</button>
</div>
</div>
</div>
<div id="layout">
<div id="layout-menu-container">
<div id="layout-menu">
<div class="menu-item"><a href="javascript:void(0)" class="closebtn" onclick="closeNav()">×</a></div>
<div class="menu-item"><a href="index.html">About</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="experience.html">Experiences</a></div>
<div class="menu-item"><a href="assets/cv.pdf">CV</a></div>
</div> <!-- <div id="layout-menu"> -->
</div> <!-- <div id="layout-menu-container"> -->
<div id="layout-content-container">
<div id="layout-content">
<div id="toptitle">
<h1>Publications </h1>
</div>
<ul>
<li><p>FAM Diffusion: Frequency and Attention Modulation for High-Resolution Image Generation with Stable Diffusion <br />
H. Yang, A. Bulat, I. Hadji, <b>H. X. Pham</b>, X. Zhu, G. Tzimiropoulos and B. Martinez <br />
to appear in CVPR 2025 [<a href="https://arxiv.org/abs/2411.18552">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Graph Guided Question Answer Generation for Procedural Question-Answering <br />
<b>H. X. Pham</b>, I. Hadji, X. Xu, Z. Degutyte, J. Rainey, E. Kazakos, A. Fazly, G. Tzimiropoulos and B. Martinez <br />
appeared in EACL 2024 (oral presentation) [<a href="https://aclanthology.org/2024.eacl-long.154/">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Flow Graph to Video Grounding for Weakly-Supervised Multi-step Localization <br />
N. Dvornik, I. Hadji, <b>H. X. Pham</b>, D. Bhatt, B. Martinez, A. Fazly and Allan D. Jepson <br />
appeared in ECCV 2022 (oral presentation) [<a href="https://arxiv.org/abs/2210.04996">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Variational Continual Proxy-Anchor for Deep Metric Learning <br />
M. Kim, R. Guerrero*, <b>H. X. Pham</b>* and V. Pavlovic <br />
appeared in AISTATS 2022 [<a href="https://proceedings.mlr.press/v151/kim22d/kim22d.pdf">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Cross-modal Retrieval and Synthesis (X-MRS): Closing the Modality Gap in Shared Subspace Learning <br />
R. Guerrero*, <b>H. X. Pham</b>* and V. Pavlovic <br />
appeared in ACM Multimedia 2021 [<a href="https://arxiv.org/abs/2012.01345">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>CHEF: Cross-modal Hierarchical Embeddings for Food Domain Retrieval <br />
<b>H. X. Pham</b>, R. Guerrero, J. Li and V. Pavlovic <br />
appeared in AAAI 2021 [<a href="https://arxiv.org/abs/2102.02547">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Learning Continuous Facial Actions From Speech for Real-Time Animation <br />
<b>H. X. Pham</b>, Y. Wang and V. Pavlovic <br />
in IEEE Transactions on Affective Computing, vol. 13, no. 3, pp. 1567-1580, 1 July-Sept. 2022 [<a href="https://ieeexplore.ieee.org/document/9186776">paper</a>]</p>
</li>
</ul>
<h3>Before 2019</h3>
<ul>
<li><p>Generative Adversarial Talking Head: Bringing Portrait To Life with a Weakly Supervised Neural Network <br />
<b>H. X. Pham</b>. Y. Wang and V. Pavlovic <br />
in arXiv, 2018 [<a href="https://arxiv.org/abs/1803.07716">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>End-to-end Learning for 3D Facial Animation from Speech <br />
<b>H. X. Pham</b>, Y. Wang and V. Pavlovic <br />
appeared in International Conference in Multimodal Interaction (ICMI), Oct 2018. [<a href="https://dl.acm.org/doi/abs/10.1145/3242969.3243017">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Using 3D Face Priors for Depth Recovery <br />
C. Chen*, <b>H. X. Pham</b>*, V. Pavlovic, J. Cai, G. Shi, Y. Gao and H. Cheng
in Journal of Visual Communication and Image Representation, Vol 48, Oct 2017. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320317301335">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Speech-driven 3D Facial Animation with Implicit Emotional Awareness: A Deep Learning Approach <br />
<b>H. X. Pham</b>, S. Cheung and V. Pavlovic <br />
in CVPRW 2017 [<a href="https://openaccess.thecvf.com/content<u>cvpr</u>2017<u>workshops/w41/papers/Pavlovic</u>Speech-Driven<u>3D</u>Facial<u>CVPR</u>2017_paper.pdf">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Robust Real-Time 3D Face Tracking from RGBD Videos under Extreme Pose, Depth, and Expression Variations <br />
<b>H. X. Pham</b> and V. Pavlovic <br />
in International Conference in 3D Vision (3DV), 2016 [<a href="https://ieeexplore.ieee.org/document/7785119">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Robust Real-time Performance-driven 3D Face Tracking <br />
<b>H. X. Pham</b>, V. Pavlovic, J. Cai and T. Cham <br />
in ICPR, 2016 [<a href="https://ieeexplore.ieee.org/document/7899906">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Depth Recover with Face Priors <br />
C. Chen*, <b>H. X. Pham</b>*, V. Pavlovic, J. Cai and G. Shi <br />
in ACCV, 2014 (oral presentation) [<a href="https://link.springer.com/chapter/10.1007/978-3-319-16817-3_22">paper</a>]</p>
</li>
</ul>
<ul>
<li><p>Hybrid On-line 3D Face and Facial Actions Tracking in RGBD Video Sequences <br />
<b>H. X. Pham</b> and V. Pavlovic <br />
in ICPR, 2014. [<a href="https://ieeexplore.ieee.org/document/6977431">paper</a>]</p>
</li>
</ul>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
Last edited  on April 22<sup>nd</sup> 2025  11:23AM (Time Zone: BST). </br>
Powered by <a href="https://github.com/szl2/jemdoc-new-design" target="blank">jemdoc + new design</a>.
</div> <!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
</div> <!-- <div id="layout-content-container"> -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>
